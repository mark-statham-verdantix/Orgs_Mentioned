{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cdb192d",
   "metadata": {},
   "source": [
    "# NER Testing and Fine-tuning Notebook\n",
    "\n",
    "This notebook provides:\n",
    "1. Testing different NER models (spaCy, Transformers, etc.)\n",
    "2. Evaluation metrics for organization extraction\n",
    "3. Fine-tuning pipelines for custom models\n",
    "4. Comparison of model performance\n",
    "5. Data preparation utilities\n",
    "\n",
    "## Installation Requirements\n",
    "```bash\n",
    "pip install spacy transformers datasets torch evaluate seqeval\n",
    "pip install spacy-transformers\n",
    "python -m spacy download en_core_web_sm\n",
    "python -m spacy download en_core_web_lg\n",
    "python -m spacy download en_core_web_trf\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f3e2b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Transformers and datasets\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForTokenClassification,\n",
    "    TrainingArguments, Trainer, DataCollatorForTokenClassification,\n",
    "    pipeline\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Evaluation\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# spaCy training\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ec2a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 25 sample texts\n",
      "Created 10 training examples\n"
     ]
    }
   ],
   "source": [
    "def create_sample_data():\n",
    "    \"\"\"Create sample data for testing and training\"\"\"\n",
    "    \n",
    "    # Sample texts with organizations\n",
    "    sample_texts = [\n",
    "        \"Microsoft Corporation announced a partnership with OpenAI to integrate AI capabilities.\",\n",
    "        \"Apple Inc. reported record quarterly earnings, outperforming Google LLC and Meta Platforms Inc.\",\n",
    "        \"JPMorgan Chase & Co. is the largest bank in the United States, followed by Bank of America Corp.\",\n",
    "        \"Tesla Inc. and General Motors Company are competing in the electric vehicle market.\",\n",
    "        \"Amazon.com Inc. acquired Whole Foods Market for $13.7 billion.\",\n",
    "        \"Salesforce Inc. is a leading cloud computing company based in San Francisco.\",\n",
    "        \"Oracle Corporation provides database software and technology solutions.\",\n",
    "        \"Netflix Inc. competes with Disney+ and HBO Max in the streaming market.\",\n",
    "        \"IBM Corporation has been a technology leader for over a century.\",\n",
    "        \"NVIDIA Corporation is known for its graphics processing units and AI chips.\",\n",
    "        \"Cisco Systems Inc. provides networking hardware and software solutions.\",\n",
    "        \"Intel Corporation manufactures semiconductors and microprocessors.\",\n",
    "        \"Adobe Inc. develops creative software including Photoshop and Illustrator.\",\n",
    "        \"PayPal Holdings Inc. facilitates online payments for millions of users.\",\n",
    "        \"Goldman Sachs Group Inc. is a leading investment banking firm.\",\n",
    "        \"Morgan Stanley provides wealth management and investment services.\",\n",
    "        \"Wells Fargo & Company is one of the largest banks in the United States.\",\n",
    "        \"Berkshire Hathaway Inc. is Warren Buffett's investment company.\",\n",
    "        \"Johnson & Johnson develops pharmaceuticals and medical devices.\",\n",
    "        \"Pfizer Inc. is a global pharmaceutical corporation.\",\n",
    "        \"The Federal Reserve announced changes to interest rates affecting all major banks.\",\n",
    "        \"Stanford University researchers collaborated with MIT on artificial intelligence.\",\n",
    "        \"Harvard Business School published a study on corporate governance.\",\n",
    "        \"The New York Stock Exchange saw heavy trading in technology stocks.\",\n",
    "        \"BlackRock Inc. is the world's largest asset management firm.\"\n",
    "    ]\n",
    "    \n",
    "    return sample_texts\n",
    "\n",
    "def create_training_data():\n",
    "    \"\"\"Create training data in spaCy format\"\"\"\n",
    "    \n",
    "    training_data = [\n",
    "        (\"Microsoft Corporation announced a partnership with OpenAI.\", \n",
    "         {\"entities\": [(0, 19, \"ORG\"), (48, 54, \"ORG\")]}),\n",
    "        \n",
    "        (\"Apple Inc. reported record quarterly earnings, outperforming Google LLC.\", \n",
    "         {\"entities\": [(0, 10, \"ORG\"), (59, 69, \"ORG\")]}),\n",
    "        \n",
    "        (\"JPMorgan Chase & Co. is the largest bank in the United States.\", \n",
    "         {\"entities\": [(0, 20, \"ORG\")]}),\n",
    "        \n",
    "        (\"Tesla Inc. and General Motors Company are competing in the market.\", \n",
    "         {\"entities\": [(0, 10, \"ORG\"), (15, 40, \"ORG\")]}),\n",
    "        \n",
    "        (\"Amazon.com Inc. acquired Whole Foods Market for $13.7 billion.\", \n",
    "         {\"entities\": [(0, 15, \"ORG\"), (25, 42, \"ORG\")]}),\n",
    "        \n",
    "        (\"Salesforce Inc. is a leading cloud computing company.\", \n",
    "         {\"entities\": [(0, 15, \"ORG\")]}),\n",
    "        \n",
    "        (\"Oracle Corporation provides database software solutions.\", \n",
    "         {\"entities\": [(0, 18, \"ORG\")]}),\n",
    "        \n",
    "        (\"Netflix Inc. competes with Disney+ and HBO Max in streaming.\", \n",
    "         {\"entities\": [(0, 12, \"ORG\"), (27, 34, \"ORG\"), (39, 46, \"ORG\")]}),\n",
    "        \n",
    "        (\"IBM Corporation has been a technology leader for decades.\", \n",
    "         {\"entities\": [(0, 15, \"ORG\")]}),\n",
    "        \n",
    "        (\"NVIDIA Corporation is known for its graphics processing units.\", \n",
    "         {\"entities\": [(0, 18, \"ORG\")]}),\n",
    "    ]\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "# Create sample data\n",
    "sample_texts = create_sample_data()\n",
    "training_data = create_training_data()\n",
    "\n",
    "print(f\"Created {len(sample_texts)} sample texts\")\n",
    "print(f\"Created {len(training_data)} training examples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a33c8d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded en_core_web_sm\n",
      "Model en_core_web_md not available. Install with: python -m spacy download en_core_web_md\n",
      "Model en_core_web_lg not available. Install with: python -m spacy download en_core_web_lg\n",
      "Model en_core_web_trf not available. Install with: python -m spacy download en_core_web_trf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dbmdz-bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dslim-bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load microsoft-deberta: Converting from SentencePiece and Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast converters: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']\n",
      "Running comprehensive NER tests...\n",
      "\n",
      "Testing en_core_web_sm...\n",
      "  Total organizations found: 11\n",
      "  Text 1: Microsoft Corporation announced a partnership with...\n",
      "    - Microsoft Corporation (confidence: 1.000)\n",
      "    - OpenAI (confidence: 1.000)\n",
      "  Text 2: Apple Inc. reported record quarterly earnings, out...\n",
      "    - Apple Inc. (confidence: 1.000)\n",
      "    - Google LLC (confidence: 1.000)\n",
      "    - Meta Platforms Inc. (confidence: 1.000)\n",
      "\n",
      "Testing dbmdz-bert...\n",
      "  Total organizations found: 12\n",
      "  Text 1: Microsoft Corporation announced a partnership with...\n",
      "    - Microsoft Corporation (confidence: 0.999)\n",
      "    - OpenAI (confidence: 0.997)\n",
      "    - AI (confidence: 0.606)\n",
      "  Text 2: Apple Inc. reported record quarterly earnings, out...\n",
      "    - Apple Inc (confidence: 1.000)\n",
      "    - Google LLC (confidence: 0.999)\n",
      "    - Meta Platforms Inc (confidence: 0.999)\n",
      "\n",
      "Testing dslim-bert...\n",
      "  Total organizations found: 11\n",
      "  Text 1: Microsoft Corporation announced a partnership with...\n",
      "    - Microsoft Corporation (confidence: 0.999)\n",
      "    - OpenAI (confidence: 0.997)\n",
      "  Text 2: Apple Inc. reported record quarterly earnings, out...\n",
      "    - Apple Inc (confidence: 1.000)\n",
      "    - Google LLC (confidence: 0.999)\n",
      "    - Meta Platforms Inc (confidence: 0.999)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class NERModelTester:\n",
    "    \"\"\"Class to test different NER models\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "    \n",
    "    def load_spacy_models(self):\n",
    "        \"\"\"Load available spaCy models\"\"\"\n",
    "        spacy_models = {\n",
    "            'en_core_web_sm': 'en_core_web_sm',\n",
    "            'en_core_web_md': 'en_core_web_md', \n",
    "            'en_core_web_lg': 'en_core_web_lg',\n",
    "            'en_core_web_trf': 'en_core_web_trf'\n",
    "        }\n",
    "        \n",
    "        for name, model_name in spacy_models.items():\n",
    "            try:\n",
    "                self.models[name] = spacy.load(model_name)\n",
    "                print(f\"Loaded {name}\")\n",
    "            except OSError:\n",
    "                print(f\"Model {name} not available. Install with: python -m spacy download {model_name}\")\n",
    "    \n",
    "    def load_transformer_models(self):\n",
    "        \"\"\"Load transformer-based NER models\"\"\"\n",
    "        transformer_models = {\n",
    "            'dbmdz-bert': 'dbmdz/bert-large-cased-finetuned-conll03-english',\n",
    "            'dslim-bert': 'dslim/bert-base-NER',\n",
    "            'microsoft-deberta': 'microsoft/deberta-v3-base'\n",
    "        }\n",
    "        \n",
    "        for name, model_name in transformer_models.items():\n",
    "            try:\n",
    "                tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "                model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "                self.models[name] = pipeline(\"ner\", \n",
    "                                            model=model, \n",
    "                                            tokenizer=tokenizer, \n",
    "                                            aggregation_strategy=\"simple\")\n",
    "                print(f\"Loaded {name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {name}: {str(e)}\")\n",
    "    \n",
    "    def extract_organizations_spacy(self, text, model):\n",
    "        \"\"\"Extract organizations using spaCy model\"\"\"\n",
    "        doc = model(text)\n",
    "        organizations = []\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"ORG\":\n",
    "                organizations.append({\n",
    "                    'text': ent.text,\n",
    "                    'start': ent.start_char,\n",
    "                    'end': ent.end_char,\n",
    "                    'confidence': 1.0  # spaCy doesn't provide confidence scores\n",
    "                })\n",
    "        \n",
    "        return organizations\n",
    "    \n",
    "    def extract_organizations_transformer(self, text, model):\n",
    "        \"\"\"Extract organizations using transformer model\"\"\"\n",
    "        results = model(text)\n",
    "        organizations = []\n",
    "        \n",
    "        for result in results:\n",
    "            if 'ORG' in result['entity_group'] or 'ORGANIZATION' in result['entity_group']:\n",
    "                organizations.append({\n",
    "                    'text': result['word'],\n",
    "                    'start': result['start'],\n",
    "                    'end': result['end'],\n",
    "                    'confidence': result['score']\n",
    "                })\n",
    "        \n",
    "        return organizations\n",
    "    \n",
    "    def test_model_on_texts(self, model_name, texts):\n",
    "        \"\"\"Test a specific model on sample texts\"\"\"\n",
    "        model = self.models[model_name]\n",
    "        results = []\n",
    "        \n",
    "        for text in texts:\n",
    "            if 'spacy' in model_name or isinstance(model, spacy.lang.en.English):\n",
    "                orgs = self.extract_organizations_spacy(text, model)\n",
    "            else:\n",
    "                orgs = self.extract_organizations_transformer(text, model)\n",
    "            \n",
    "            results.append({\n",
    "                'text': text,\n",
    "                'organizations': orgs,\n",
    "                'org_count': len(orgs)\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def run_comprehensive_test(self, texts):\n",
    "        \"\"\"Run tests on all available models\"\"\"\n",
    "        print(\"Running comprehensive NER tests...\\n\")\n",
    "        \n",
    "        for model_name in self.models.keys():\n",
    "            print(f\"Testing {model_name}...\")\n",
    "            try:\n",
    "                results = self.test_model_on_texts(model_name, texts[:5])  # Test on first 5 texts\n",
    "                self.results[model_name] = results\n",
    "                \n",
    "                # Print summary\n",
    "                total_orgs = sum([r['org_count'] for r in results])\n",
    "                print(f\"  Total organizations found: {total_orgs}\")\n",
    "                \n",
    "                # Show examples\n",
    "                for i, result in enumerate(results[:2]):\n",
    "                    print(f\"  Text {i+1}: {result['text'][:50]}...\")\n",
    "                    for org in result['organizations']:\n",
    "                        print(f\"    - {org['text']} (confidence: {org['confidence']:.3f})\")\n",
    "                \n",
    "                print()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Error testing {model_name}: {str(e)}\\n\")\n",
    "\n",
    "# Initialize and test models\n",
    "tester = NERModelTester()\n",
    "tester.load_spacy_models()\n",
    "tester.load_transformer_models()\n",
    "\n",
    "# Run tests\n",
    "tester.run_comprehensive_test(sample_texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
