{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Discovery Testing Notebook\n",
    "\n",
    "This notebook tests the \"Potential New Organizations\" discovery functionality from the Streamlit app.\n",
    "It allows you to test the NER extraction logic, fuzzy matching, and filtering rules in isolation.\n",
    "\n",
    "## Features:\n",
    "1. Test NER extraction with the same model used in the app\n",
    "2. Test fuzzy matching against database organizations\n",
    "3. Examine filtering rules (generic terms, short terms, etc.)\n",
    "4. Debug why organizations appear/disappear between runs\n",
    "5. Test with sample documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import the same libraries used in the Streamlit app\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a Simplified OrganizationExtractor Class for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestOrganizationExtractor:\n",
    "    \"\"\"Simplified version of OrganizationExtractor for testing NER discovery\"\"\"\n",
    "    \n",
    "    def __init__(self, postgres_config: Dict[str, str] = None):\n",
    "        self.min_confidence = 0.85\n",
    "        self.min_org_length = 3\n",
    "        \n",
    "        # Initialize components\n",
    "        self.master_orgs_df = pd.DataFrame()\n",
    "        self.org_lookup = {}\n",
    "        self.known_short_orgs = set()\n",
    "        self.tokenizer = None\n",
    "        self.ner_model = None\n",
    "        \n",
    "        # Initialize system\n",
    "        self._initialize_system(postgres_config)\n",
    "    \n",
    "    def _initialize_system(self, postgres_config):\n",
    "        \"\"\"Initialize system components\"\"\"\n",
    "        try:\n",
    "            # Initialize tokenizer\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "            \n",
    "            # Load NER model (same as in the app)\n",
    "            self.ner_model = pipeline(\n",
    "                \"ner\",\n",
    "                model=\"dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
    "                aggregation_strategy=\"simple\",\n",
    "                device=-1\n",
    "            )\n",
    "            \n",
    "            # Load organizations from database or use sample data\n",
    "            if postgres_config:\n",
    "                self._load_organizations_from_db(postgres_config)\n",
    "            else:\n",
    "                self._load_sample_organizations()\n",
    "            \n",
    "            self._build_lookup()\n",
    "            print(f\"Initialized with {len(self.master_orgs_df)} organizations in database\")\n",
    "            print(f\"Created {len(self.org_lookup)} lookup entries\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"System initialization failed: {e}\")\n",
    "    \n",
    "    def _load_organizations_from_db(self, postgres_config):\n",
    "        \"\"\"Load organizations from database\"\"\"\n",
    "        try:\n",
    "            conn = psycopg2.connect(\n",
    "                host=postgres_config['host'],\n",
    "                port=postgres_config.get('port', 5432),\n",
    "                database=postgres_config['database'],\n",
    "                user=postgres_config['user'],\n",
    "                password=postgres_config['password']\n",
    "            )\n",
    "            \n",
    "            query = \"\"\"\n",
    "            SELECT org_id, org_name\n",
    "            FROM verdantix.org\n",
    "            WHERE org_name IS NOT NULL \n",
    "                AND LENGTH(TRIM(org_name)) > 2\n",
    "            ORDER BY org_name\n",
    "            \"\"\"\n",
    "            \n",
    "            self.master_orgs_df = pd.read_sql_query(query, conn)\n",
    "            conn.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Database connection failed: {e}\")\n",
    "            print(\"Using sample data instead...\")\n",
    "            self._load_sample_organizations()\n",
    "    \n",
    "    def _load_sample_organizations(self):\n",
    "        \"\"\"Load sample organizations for testing\"\"\"\n",
    "        sample_orgs = [\n",
    "            {'org_id': 1, 'org_name': 'Microsoft Corporation'},\n",
    "            {'org_id': 2, 'org_name': 'Apple Inc.'},\n",
    "            {'org_id': 3, 'org_name': 'Google LLC'},\n",
    "            {'org_id': 4, 'org_name': 'Amazon.com Inc.'},\n",
    "            {'org_id': 5, 'org_name': 'Meta Platforms Inc.'},\n",
    "            {'org_id': 6, 'org_name': 'Tesla Inc.'},\n",
    "            {'org_id': 7, 'org_name': 'NVIDIA Corporation'},\n",
    "            {'org_id': 8, 'org_name': 'JPMorgan Chase & Co.'},\n",
    "            {'org_id': 9, 'org_name': 'Johnson & Johnson'},\n",
    "            {'org_id': 10, 'org_name': 'Berkshire Hathaway Inc.'},\n",
    "            {'org_id': 11, 'org_name': 'Alphabet Inc.'},\n",
    "            {'org_id': 12, 'org_name': 'Salesforce Inc.'},\n",
    "            {'org_id': 13, 'org_name': 'Oracle Corporation'},\n",
    "            {'org_id': 14, 'org_name': 'IBM'},\n",
    "            {'org_id': 15, 'org_name': 'Intel'},\n",
    "        ]\n",
    "        \n",
    "        self.master_orgs_df = pd.DataFrame(sample_orgs)\n",
    "    \n",
    "    def _generate_aliases(self, org_name: str) -> List[str]:\n",
    "        \"\"\"Generate aliases for organization names (same as in app)\"\"\"\n",
    "        aliases = []\n",
    "        \n",
    "        # Extract acronyms from parentheses\n",
    "        paren_pattern = r'\\(([^)]+)\\)'\n",
    "        paren_matches = re.findall(paren_pattern, org_name)\n",
    "        for match in paren_matches:\n",
    "            cleaned = match.strip()\n",
    "            if 2 <= len(cleaned) <= 10:\n",
    "                aliases.append(cleaned)\n",
    "        \n",
    "        # Remove business suffixes\n",
    "        suffix_patterns = [\n",
    "            r'\\s+(?:Inc\\.?|Corporation|Corp\\.?|Company|Co\\.?|Limited|Ltd\\.?)',\n",
    "            r'\\s+(?:LLC|LLP|LP|PLC|Group|Holdings?)'\n",
    "        ]\n",
    "        \n",
    "        for pattern in suffix_patterns:\n",
    "            base = re.sub(pattern + r'$', '', org_name, flags=re.IGNORECASE).strip()\n",
    "            if base != org_name and len(base) > 2:\n",
    "                aliases.append(base)\n",
    "        \n",
    "        # Create acronyms from main text\n",
    "        main_text = re.sub(paren_pattern, '', org_name).strip()\n",
    "        words = main_text.split()\n",
    "        if len(words) > 1:\n",
    "            skip_words = {'of', 'the', 'and', 'for', 'in', 'on', 'at', 'to', 'a', 'an', '&'}\n",
    "            meaningful_words = [w for w in words if w.lower() not in skip_words and len(w) > 0]\n",
    "            if len(meaningful_words) > 1:\n",
    "                acronym = ''.join([w[0].upper() for w in meaningful_words])\n",
    "                if 2 <= len(acronym) <= 8:\n",
    "                    aliases.append(acronym)\n",
    "        \n",
    "        return list(set(aliases))\n",
    "    \n",
    "    def _build_lookup(self):\n",
    "        \"\"\"Build organization lookup dictionary (same as in app)\"\"\"\n",
    "        self.org_lookup = {}\n",
    "        self.known_short_orgs = set()\n",
    "        \n",
    "        for _, org in self.master_orgs_df.iterrows():\n",
    "            org_id = org['org_id']\n",
    "            org_name = str(org['org_name']).strip()\n",
    "            \n",
    "            if len(org_name) > 2:\n",
    "                self.org_lookup[org_name.lower()] = {\n",
    "                    'org_id': org_id,\n",
    "                    'canonical': org_name,\n",
    "                    'confidence': 1.0\n",
    "                }\n",
    "                \n",
    "                # Track short orgs from database\n",
    "                if len(org_name) < 8 and ' ' not in org_name:\n",
    "                    self.known_short_orgs.add(org_name.lower())\n",
    "                \n",
    "                # Add aliases\n",
    "                aliases = self._generate_aliases(org_name)\n",
    "                for alias in aliases:\n",
    "                    if alias.lower() not in self.org_lookup and len(alias) > 2:\n",
    "                        self.org_lookup[alias.lower()] = {\n",
    "                            'org_id': org_id,\n",
    "                            'canonical': org_name,\n",
    "                            'confidence': 0.85\n",
    "                        }\n",
    "                        \n",
    "                        if len(alias) < 8 and ' ' not in alias:\n",
    "                            self.known_short_orgs.add(alias.lower())\n",
    "    \n",
    "    def _is_generic_term(self, term: str) -> bool:\n",
    "        \"\"\"Filter generic business terms (same as in app)\"\"\"\n",
    "        generic_terms = {\n",
    "            'ai', 'iot', 'esg', 'api', 'cloud', 'data', 'tech', 'digital',\n",
    "            'smart', 'green', 'cyber', 'auto', 'bio', 'blockchain', 'fintech',\n",
    "            'saas', 'crm', 'erp', 'hr', 'it', 'covid', 'gdpr'\n",
    "        }\n",
    "        return term.lower() in generic_terms\n",
    "    \n",
    "    def extract_organizations_debug(self, text: str, debug=True) -> Tuple[List[Dict], List[Dict], Dict]:\n",
    "        \"\"\"Extract organizations with detailed debugging info\"\"\"\n",
    "        \n",
    "        debug_info = {\n",
    "            'text_length': len(text),\n",
    "            'ner_predictions': [],\n",
    "            'db_exact_matches': [],\n",
    "            'fuzzy_matches': [],\n",
    "            'filtered_out': [],\n",
    "            'final_discoveries': []\n",
    "        }\n",
    "        \n",
    "        db_matches = []\n",
    "        ner_discoveries = []\n",
    "        \n",
    "        # Method 1: Database matches (exact)\n",
    "        text_lower = text.lower()\n",
    "        sorted_terms = sorted(self.org_lookup.keys(), key=len, reverse=True)\n",
    "        matched_positions = set()\n",
    "        \n",
    "        for term in sorted_terms:\n",
    "            if (len(term) >= self.min_org_length and \n",
    "                not self._is_generic_term(term)):\n",
    "                \n",
    "                # Short term filtering\n",
    "                if len(term) < 8 and ' ' not in term:\n",
    "                    if term.lower() not in self.known_short_orgs:\n",
    "                        if debug:\n",
    "                            debug_info['filtered_out'].append({\n",
    "                                'term': term,\n",
    "                                'reason': 'short_term_not_in_known_list'\n",
    "                            })\n",
    "                        continue\n",
    "                \n",
    "                pattern = r'\\b' + re.escape(term) + r'\\b'\n",
    "                \n",
    "                for match in re.finditer(pattern, text_lower):\n",
    "                    start, end = match.span()\n",
    "                    \n",
    "                    if not any(start < e and s < end for s, e in matched_positions):\n",
    "                        matched_positions.add((start, end))\n",
    "                        \n",
    "                        org_info = self.org_lookup[term]\n",
    "                        \n",
    "                        match_data = {\n",
    "                            'text': text[start:end],\n",
    "                            'canonical': org_info['canonical'],\n",
    "                            'confidence': org_info['confidence'],\n",
    "                            'org_id': org_info['org_id'],\n",
    "                            'method': 'database'\n",
    "                        }\n",
    "                        \n",
    "                        db_matches.append(match_data)\n",
    "                        \n",
    "                        if debug:\n",
    "                            debug_info['db_exact_matches'].append(match_data)\n",
    "        \n",
    "        # Method 2: NER for new organizations\n",
    "        if self.ner_model:\n",
    "            try:\n",
    "                if len(text) > 4000:\n",
    "                    chunks = [text[i:i+4000] for i in range(0, len(text), 3500)]\n",
    "                else:\n",
    "                    chunks = [text]\n",
    "                \n",
    "                for chunk in chunks:\n",
    "                    predictions = self.ner_model(chunk)\n",
    "                    \n",
    "                    if debug:\n",
    "                        debug_info['ner_predictions'].extend(predictions)\n",
    "                    \n",
    "                    for pred in predictions:\n",
    "                        if 'ORG' in pred.get('entity_group', ''):\n",
    "                            org_text = pred['word'].strip()\n",
    "                            \n",
    "                            # Clean tokenization artifacts\n",
    "                            org_text = re.sub(r'^##', '', org_text)\n",
    "                            org_text = re.sub(r'[^\\w\\s&.-]', '', org_text)\n",
    "                            org_text = ' '.join(org_text.split())\n",
    "                            \n",
    "                            if (len(org_text) >= self.min_org_length and\n",
    "                                pred['score'] >= self.min_confidence and\n",
    "                                not self._is_generic_term(org_text)):\n",
    "                                \n",
    "                                # Check if already in database\n",
    "                                if org_text.lower() not in self.org_lookup:\n",
    "                                    # Try fuzzy matching with consistent results\n",
    "                                    if len(self.master_orgs_df) > 0:\n",
    "                                        canonical_names = self.master_orgs_df['org_name'].tolist()\n",
    "                                        \n",
    "                                        # Sort for deterministic results\n",
    "                                        canonical_names = sorted(canonical_names)\n",
    "                                        \n",
    "                                        best_match = process.extractOne(\n",
    "                                            org_text, canonical_names, scorer=fuzz.ratio\n",
    "                                        )\n",
    "                                        \n",
    "                                        fuzzy_score = best_match[1] if best_match else 0\n",
    "                                        \n",
    "                                        fuzzy_info = {\n",
    "                                            'org_text': org_text,\n",
    "                                            'best_match': best_match[0] if best_match else None,\n",
    "                                            'fuzzy_score': fuzzy_score,\n",
    "                                            'ner_confidence': pred['score']\n",
    "                                        }\n",
    "                                        \n",
    "                                        if debug:\n",
    "                                            debug_info['fuzzy_matches'].append(fuzzy_info)\n",
    "                                        \n",
    "                                        if best_match and best_match[1] >= 85:\n",
    "                                            # Close match found - add to DB matches\n",
    "                                            matched_row = self.master_orgs_df[\n",
    "                                                self.master_orgs_df['org_name'] == best_match[0]\n",
    "                                            ].iloc[0]\n",
    "                                            \n",
    "                                            fuzzy_match_data = {\n",
    "                                                'text': org_text,\n",
    "                                                'canonical': matched_row['org_name'],\n",
    "                                                'confidence': pred['score'] * (best_match[1] / 100),\n",
    "                                                'org_id': matched_row['org_id'],\n",
    "                                                'method': 'ner_fuzzy',\n",
    "                                                'fuzzy_score': fuzzy_score\n",
    "                                            }\n",
    "                                            \n",
    "                                            db_matches.append(fuzzy_match_data)\n",
    "                                        else:\n",
    "                                            # New organization discovery\n",
    "                                            discovery_data = {\n",
    "                                                'text': org_text,\n",
    "                                                'confidence': pred['score'],\n",
    "                                                'method': 'ner_new',\n",
    "                                                'best_fuzzy_match': best_match[0] if best_match else None,\n",
    "                                                'fuzzy_score': fuzzy_score\n",
    "                                            }\n",
    "                                            \n",
    "                                            ner_discoveries.append(discovery_data)\n",
    "                                            \n",
    "                                            if debug:\n",
    "                                                debug_info['final_discoveries'].append(discovery_data)\n",
    "                                else:\n",
    "                                    if debug:\n",
    "                                        debug_info['filtered_out'].append({\n",
    "                                            'term': org_text,\n",
    "                                            'reason': 'already_in_database'\n",
    "                                        })\n",
    "                            else:\n",
    "                                if debug:\n",
    "                                    reasons = []\n",
    "                                    if len(org_text) < self.min_org_length:\n",
    "                                        reasons.append('too_short')\n",
    "                                    if pred['score'] < self.min_confidence:\n",
    "                                        reasons.append('low_confidence')\n",
    "                                    if self._is_generic_term(org_text):\n",
    "                                        reasons.append('generic_term')\n",
    "                                    \n",
    "                                    debug_info['filtered_out'].append({\n",
    "                                        'term': org_text,\n",
    "                                        'reason': ', '.join(reasons),\n",
    "                                        'confidence': pred['score']\n",
    "                                    })\n",
    "            \n",
    "            except Exception as e:\n",
    "                if debug:\n",
    "                    debug_info['error'] = str(e)\n",
    "        \n",
    "        # Deduplicate\n",
    "        db_matches = self._deduplicate_matches(db_matches)\n",
    "        ner_discoveries = self._deduplicate_matches(ner_discoveries)\n",
    "        \n",
    "        return db_matches, ner_discoveries, debug_info\n",
    "    \n",
    "    def _deduplicate_matches(self, matches: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Remove duplicate matches (same as in app)\"\"\"\n",
    "        seen = set()\n",
    "        deduplicated = []\n",
    "        \n",
    "        for match in sorted(matches, key=lambda x: x['confidence'], reverse=True):\n",
    "            canonical = match.get('canonical', match['text']).lower()\n",
    "            if canonical not in seen:\n",
    "                seen.add(canonical)\n",
    "                deduplicated.append(match)\n",
    "        \n",
    "        return deduplicated\n",
    "\n",
    "print(\"TestOrganizationExtractor class created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the Test Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to connect to database, fall back to sample data if not available\n",
    "postgres_config = None\n",
    "try:\n",
    "    postgres_config = {\n",
    "        'host': os.getenv('POSTGRES_HOST', 'localhost'),\n",
    "        'port': os.getenv('POSTGRES_PORT', '5432'),\n",
    "        'database': os.getenv('POSTGRES_DATABASE', 'postgres'),\n",
    "        'user': os.getenv('POSTGRES_USER', 'postgres'),\n",
    "        'password': os.getenv('POSTGRES_PASSWORD', '')\n",
    "    }\n",
    "    \n",
    "    # Test connection\n",
    "    if not all([postgres_config['host'], postgres_config['user'], postgres_config['password']]):\n",
    "        print(\"Database credentials not complete, using sample data\")\n",
    "        postgres_config = None\n",
    "except Exception as e:\n",
    "    print(f\"Database connection failed: {e}\")\n",
    "    postgres_config = None\n",
    "\n",
    "# Initialize extractor\n",
    "print(\"Initializing test extractor...\")\n",
    "extractor = TestOrganizationExtractor(postgres_config)\n",
    "print(\"\\nExtractor ready!\")\n",
    "print(f\"Database organizations loaded: {len(extractor.master_orgs_df)}\")\n",
    "print(f\"Lookup entries created: {len(extractor.org_lookup)}\")\n",
    "print(f\"Known short orgs: {len(extractor.known_short_orgs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Sample Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample test texts - mix of known and unknown organizations\n",
    "test_texts = [\n",
    "    # Text with mix of known and potentially unknown orgs\n",
    "    \"Microsoft Corporation announced a partnership with Acme Digital Solutions to develop AI capabilities. The collaboration also involves DataTech Innovations and CloudFlow Systems.\",\n",
    "    \n",
    "    # Text with variations of known company names\n",
    "    \"Apple Inc reported strong earnings, outperforming Google and Meta. Tesla's stock price also rose following the announcement.\",\n",
    "    \n",
    "    # Text with potentially new organizations\n",
    "    \"Quantum Computing Solutions partnered with BioTech Laboratories to advance medical research. The initiative is supported by Green Energy Partners and Smart City Technologies.\",\n",
    "    \n",
    "    # Text with short terms and acronyms\n",
    "    \"IBM and AWS are competing with GCP in the cloud market. The CEO of AMD commented on the partnership between HPE and Dell.\",\n",
    "    \n",
    "    # Complex text with many organizations\n",
    "    \"The merger between Innovative Software Corp and Digital Transformation Ltd was approved by RegTech Compliance Services. This follows recent acquisitions by Enterprise Solutions Group and Data Analytics Partners.\"\n",
    "]\n",
    "\n",
    "print(f\"Created {len(test_texts)} test texts for analysis\")\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    print(f\"\\nText {i}: {text[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run NER Discovery Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(text, title=\"\"):\n",
    "    \"\"\"Analyze a single text and show detailed results\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ANALYZING: {title}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"TEXT: {text}\")\n",
    "    print(f\"Length: {len(text)} characters\")\n",
    "    \n",
    "    # Run extraction with debug info\n",
    "    db_matches, ner_discoveries, debug_info = extractor.extract_organizations_debug(text, debug=True)\n",
    "    \n",
    "    print(f\"\\n📊 SUMMARY:\")\n",
    "    print(f\"  Database Matches: {len(db_matches)}\")\n",
    "    print(f\"  New Discoveries: {len(ner_discoveries)}\")\n",
    "    print(f\"  Total NER Predictions: {len(debug_info['ner_predictions'])}\")\n",
    "    print(f\"  Filtered Out: {len(debug_info['filtered_out'])}\")\n",
    "    \n",
    "    # Show database matches\n",
    "    if db_matches:\n",
    "        print(f\"\\n✅ DATABASE MATCHES ({len(db_matches)}):\")\n",
    "        for i, match in enumerate(db_matches, 1):\n",
    "            method_icon = \"🎯\" if match['method'] == 'database' else \"🔍\"\n",
    "            print(f\"  {i}. {method_icon} '{match['text']}' → {match['canonical']} (conf: {match['confidence']:.3f}, method: {match['method']})\")\n",
    "            if 'fuzzy_score' in match:\n",
    "                print(f\"      Fuzzy score: {match['fuzzy_score']}%\")\n",
    "    \n",
    "    # Show new discoveries\n",
    "    if ner_discoveries:\n",
    "        print(f\"\\n🔍 POTENTIAL NEW ORGANIZATIONS ({len(ner_discoveries)}):\")\n",
    "        for i, discovery in enumerate(ner_discoveries, 1):\n",
    "            print(f\"  {i}. 🆕 '{discovery['text']}' (conf: {discovery['confidence']:.3f})\")\n",
    "            if discovery.get('fuzzy_score', 0) > 0:\n",
    "                print(f\"      Closest match: '{discovery['best_fuzzy_match']}' ({discovery['fuzzy_score']}%)\")\n",
    "            else:\n",
    "                print(f\"      No close matches found\")\n",
    "    \n",
    "    # Show fuzzy matching details\n",
    "    if debug_info['fuzzy_matches']:\n",
    "        print(f\"\\n🔍 FUZZY MATCHING DETAILS:\")\n",
    "        for fuzzy in debug_info['fuzzy_matches']:\n",
    "            status = \"✅ Matched (≥85%)\" if fuzzy['fuzzy_score'] >= 85 else \"❌ No match (<85%)\"\n",
    "            print(f\"  '{fuzzy['org_text']}' → '{fuzzy['best_match']}' ({fuzzy['fuzzy_score']}%) {status}\")\n",
    "    \n",
    "    # Show filtered out items\n",
    "    if debug_info['filtered_out']:\n",
    "        print(f\"\\n❌ FILTERED OUT ({len(debug_info['filtered_out'])}):\")\n",
    "        for filtered in debug_info['filtered_out'][:10]:  # Show first 10\n",
    "            conf_str = f\" (conf: {filtered.get('confidence', 'N/A'):.3f})\" if 'confidence' in filtered else \"\"\n",
    "            print(f\"  '{filtered['term']}' - {filtered['reason']}{conf_str}\")\n",
    "        if len(debug_info['filtered_out']) > 10:\n",
    "            print(f\"  ... and {len(debug_info['filtered_out']) - 10} more\")\n",
    "    \n",
    "    return db_matches, ner_discoveries, debug_info\n",
    "\n",
    "# Test each text\n",
    "all_results = []\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    db_matches, ner_discoveries, debug_info = analyze_text(text, f\"Test Text {i}\")\n",
    "    all_results.append({\n",
    "        'text': text,\n",
    "        'db_matches': db_matches,\n",
    "        'ner_discoveries': ner_discoveries,\n",
    "        'debug_info': debug_info\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Consistency - Run Same Text Multiple Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_consistency(text, runs=3):\n",
    "    \"\"\"Test if the same text produces consistent results across multiple runs\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"CONSISTENCY TEST - {runs} RUNS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"TEXT: {text[:100]}...\")\n",
    "    \n",
    "    results = []\n",
    "    for run in range(runs):\n",
    "        print(f\"\\n--- Run {run + 1} ---\")\n",
    "        db_matches, ner_discoveries, debug_info = extractor.extract_organizations_debug(text, debug=False)\n",
    "        \n",
    "        run_result = {\n",
    "            'run': run + 1,\n",
    "            'db_matches': len(db_matches),\n",
    "            'ner_discoveries': len(ner_discoveries),\n",
    "            'db_orgs': [m['canonical'] for m in db_matches],\n",
    "            'new_orgs': [d['text'] for d in ner_discoveries],\n",
    "            'fuzzy_matches': [m for m in db_matches if m.get('method') == 'ner_fuzzy']\n",
    "        }\n",
    "        \n",
    "        results.append(run_result)\n",
    "        \n",
    "        print(f\"  DB matches: {run_result['db_matches']}\")\n",
    "        print(f\"  New discoveries: {run_result['ner_discoveries']}\")\n",
    "        print(f\"  Fuzzy matches: {len(run_result['fuzzy_matches'])}\")\n",
    "        \n",
    "        if run_result['new_orgs']:\n",
    "            print(f\"  New orgs: {run_result['new_orgs']}\")\n",
    "    \n",
    "    # Check consistency\n",
    "    print(f\"\\n📊 CONSISTENCY ANALYSIS:\")\n",
    "    \n",
    "    # Check if counts are consistent\n",
    "    db_counts = [r['db_matches'] for r in results]\n",
    "    discovery_counts = [r['ner_discoveries'] for r in results]\n",
    "    \n",
    "    db_consistent = len(set(db_counts)) == 1\n",
    "    discovery_consistent = len(set(discovery_counts)) == 1\n",
    "    \n",
    "    print(f\"  DB match counts: {db_counts} - {'✅ Consistent' if db_consistent else '❌ Inconsistent'}\")\n",
    "    print(f\"  Discovery counts: {discovery_counts} - {'✅ Consistent' if discovery_consistent else '❌ Inconsistent'}\")\n",
    "    \n",
    "    # Check if specific organizations are consistent\n",
    "    all_db_orgs = set()\n",
    "    all_new_orgs = set()\n",
    "    \n",
    "    for r in results:\n",
    "        all_db_orgs.update(r['db_orgs'])\n",
    "        all_new_orgs.update(r['new_orgs'])\n",
    "    \n",
    "    # Check for organizations that appear in some runs but not others\n",
    "    inconsistent_db = []\n",
    "    inconsistent_new = []\n",
    "    \n",
    "    for org in all_db_orgs:\n",
    "        appearances = sum(1 for r in results if org in r['db_orgs'])\n",
    "        if appearances != runs:\n",
    "            inconsistent_db.append((org, appearances))\n",
    "    \n",
    "    for org in all_new_orgs:\n",
    "        appearances = sum(1 for r in results if org in r['new_orgs'])\n",
    "        if appearances != runs:\n",
    "            inconsistent_new.append((org, appearances))\n",
    "    \n",
    "    if inconsistent_db:\n",
    "        print(f\"\\n❌ INCONSISTENT DB MATCHES:\")\n",
    "        for org, count in inconsistent_db:\n",
    "            print(f\"  '{org}' appeared in {count}/{runs} runs\")\n",
    "    \n",
    "    if inconsistent_new:\n",
    "        print(f\"\\n❌ INCONSISTENT NEW DISCOVERIES:\")\n",
    "        for org, count in inconsistent_new:\n",
    "            print(f\"  '{org}' appeared in {count}/{runs} runs\")\n",
    "    \n",
    "    if not inconsistent_db and not inconsistent_new:\n",
    "        print(f\"\\n✅ ALL RESULTS PERFECTLY CONSISTENT!\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test consistency on the first test text\n",
    "consistency_results = test_consistency(test_texts[0], runs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Fuzzy Matching Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fuzzy_matching():\n",
    "    \"\"\"Test fuzzy matching behavior with edge cases\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FUZZY MATCHING TESTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Test cases with variations of known company names\n",
    "    fuzzy_test_cases = [\n",
    "        # Slight variations that should match\n",
    "        \"Microsoft Corp announced new products\",\n",
    "        \"Apple Computer reported strong earnings\", \n",
    "        \"Google Inc is expanding globally\",\n",
    "        \"Amazon Web Services launched new features\",\n",
    "        \n",
    "        # Edge cases near the 85% threshold\n",
    "        \"Microsft Corporation has a typo\",  # Typo\n",
    "        \"Appple Inc has double p\",  # Typo\n",
    "        \"Micros Corp is very short\",  # Shortened\n",
    "        \"Apple Technology Inc\",  # Added words\n",
    "        \n",
    "        # Cases that shouldn't match\n",
    "        \"Microsoft Technologies Solutions Group\",  # Too different\n",
    "        \"Apple Fruit Company\",  # Different context\n",
    "    ]\n",
    "    \n",
    "    for i, test_case in enumerate(fuzzy_test_cases, 1):\n",
    "        print(f\"\\nTest {i}: {test_case}\")\n",
    "        \n",
    "        db_matches, ner_discoveries, debug_info = extractor.extract_organizations_debug(test_case, debug=True)\n",
    "        \n",
    "        # Show what was found by NER first\n",
    "        ner_orgs = [pred['word'].strip() for pred in debug_info['ner_predictions'] if 'ORG' in pred.get('entity_group', '')]\n",
    "        print(f\"  NER found: {ner_orgs}\")\n",
    "        \n",
    "        # Show fuzzy matching results\n",
    "        for fuzzy in debug_info['fuzzy_matches']:\n",
    "            result = \"→ DB MATCH\" if fuzzy['fuzzy_score'] >= 85 else \"→ NEW ORG\"\n",
    "            print(f\"  '{fuzzy['org_text']}' ~ '{fuzzy['best_match']}' ({fuzzy['fuzzy_score']}%) {result}\")\n",
    "        \n",
    "        # Show final categorization\n",
    "        if db_matches:\n",
    "            fuzzy_matches = [m for m in db_matches if m.get('method') == 'ner_fuzzy']\n",
    "            if fuzzy_matches:\n",
    "                print(f\"  ✅ Fuzzy matched to DB: {[m['canonical'] for m in fuzzy_matches]}\")\n",
    "        \n",
    "        if ner_discoveries:\n",
    "            print(f\"  🆕 New discoveries: {[d['text'] for d in ner_discoveries]}\")\n",
    "        \n",
    "        if not db_matches and not ner_discoveries:\n",
    "            print(f\"  ❌ No organizations found\")\n",
    "\n",
    "test_fuzzy_matching()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_test():\n",
    "    \"\"\"Interactive testing function\"\"\"\n",
    "    print(\"\\n🧪 INTERACTIVE TESTING\")\n",
    "    print(\"Enter text to analyze (or 'quit' to stop):\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            user_text = input(\"\\nEnter text: \").strip()\n",
    "            \n",
    "            if user_text.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"Goodbye!\")\n",
    "                break\n",
    "            \n",
    "            if not user_text:\n",
    "                continue\n",
    "            \n",
    "            db_matches, ner_discoveries, debug_info = analyze_text(user_text, \"Interactive Test\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nGoodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "# Uncomment the line below to run interactive testing\n",
    "# interactive_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary():\n",
    "    \"\"\"Create summary of all tests\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TESTING SUMMARY & INSIGHTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\n📊 EXTRACTOR CONFIGURATION:\")\n",
    "    print(f\"  Min confidence: {extractor.min_confidence}\")\n",
    "    print(f\"  Min org length: {extractor.min_org_length}\")\n",
    "    print(f\"  Fuzzy match threshold: 85%\")\n",
    "    print(f\"  Database orgs: {len(extractor.master_orgs_df)}\")\n",
    "    print(f\"  Lookup entries: {len(extractor.org_lookup)}\")\n",
    "    print(f\"  Known short orgs: {len(extractor.known_short_orgs)}\")\n",
    "    \n",
    "    # Analyze all test results\n",
    "    total_db_matches = sum(len(r['db_matches']) for r in all_results)\n",
    "    total_discoveries = sum(len(r['ner_discoveries']) for r in all_results)\n",
    "    total_fuzzy_matches = sum(len([m for m in r['db_matches'] if m.get('method') == 'ner_fuzzy']) for r in all_results)\n",
    "    \n",
    "    print(f\"\\n📈 TEST RESULTS ACROSS {len(all_results)} TEXTS:\")\n",
    "    print(f\"  Total DB matches: {total_db_matches}\")\n",
    "    print(f\"  Total new discoveries: {total_discoveries}\")\n",
    "    print(f\"  Fuzzy matches: {total_fuzzy_matches}\")\n",
    "    \n",
    "    # Show all unique new discoveries\n",
    "    all_discoveries = set()\n",
    "    for r in all_results:\n",
    "        all_discoveries.update(d['text'] for d in r['ner_discoveries'])\n",
    "    \n",
    "    if all_discoveries:\n",
    "        print(f\"\\n🆕 ALL UNIQUE NEW DISCOVERIES ({len(all_discoveries)}):\")\n",
    "        for discovery in sorted(all_discoveries):\n",
    "            print(f\"  • {discovery}\")\n",
    "    \n",
    "    print(f\"\\n💡 KEY INSIGHTS FOR DEBUGGING STREAMLIT APP:\")\n",
    "    print(f\"  1. Check if fuzzy matching is causing inconsistency (orgs moving between categories)\")\n",
    "    print(f\"  2. Verify database connection and org loading\")\n",
    "    print(f\"  3. Look for session state issues with approved/rejected lists\")\n",
    "    print(f\"  4. Test with your actual documents to see real-world behavior\")\n",
    "    print(f\"  5. Monitor fuzzy scores near the 85% threshold for edge cases\")\n",
    "    \n",
    "    print(f\"\\n🔧 RECOMMENDATIONS:\")\n",
    "    print(f\"  • Add fuzzy score logging in Streamlit app debug mode\")\n",
    "    print(f\"  • Consider making fuzzy threshold configurable\")\n",
    "    print(f\"  • Add consistency checks for multiple runs\")\n",
    "    print(f\"  • Monitor session state variables more carefully\")\n",
    "\n",
    "create_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test with Your Own Text\n",
    "\n",
    "Use the cell below to test with your own text or document content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with your own test text\n",
    "your_text = \"\"\"\n",
    "Paste your document text here to test the NER discovery functionality.\n",
    "This could be content from a PDF, Word doc, or any other document you're \n",
    "testing in the Streamlit app.\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment and modify the text above, then run this cell\n",
    "if your_text.strip() and \"Paste your document\" not in your_text:\n",
    "    print(\"Testing your custom text...\")\n",
    "    db_matches, ner_discoveries, debug_info = analyze_text(your_text, \"Your Custom Text\")\n",
    "else:\n",
    "    print(\"Replace the text above with your own content to test!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}